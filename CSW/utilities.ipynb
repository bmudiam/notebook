{
 "metadata": {
  "name": "",
  "signature": "sha256:35fb5c93768af071109d83dec83548e271fabfb7b0dcc232b07fb43bcd5d0af1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Standard Library.\n",
      "from lxml import etree\n",
      "from io import BytesIO\n",
      "from warnings import warn\n",
      "try:\n",
      "    from urllib.request import urlopen\n",
      "except ImportError:\n",
      "    from urllib import urlopen\n",
      "\n",
      "# Scientific stack.\n",
      "import numpy as np\n",
      "from pandas import DataFrame, concat, read_csv\n",
      "\n",
      "# Custom IOOS/ASA modules (available at PyPI).\n",
      "from owslib import fes\n",
      "from owslib.ows import ExceptionReport"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Constants and definitions.\n",
      "# Now we need to specify all the names we know for water level, names that\n",
      "# will get used in the CSW search, and also to find data in the datasets that\n",
      "# are returned.  This is ugly and fragile.  There hopefully will be a better\n",
      "# way in the future...\n",
      "\n",
      "name_list = ['water_surface_height_above_reference_datum',\n",
      "             'sea_surface_height_above_geoid',\n",
      "             'sea_surface_elevation',\n",
      "             'sea_surface_height_above_reference_ellipsoid',\n",
      "             'sea_surface_height_above_sea_level',\n",
      "             'sea_surface_height',\n",
      "             'water level']\n",
      "\n",
      "sos_name = 'water_surface_height_above_reference_datum'\n",
      "\n",
      "\n",
      "def get_Coops_longName(sta):\n",
      "    \"\"\"Get longName for specific station from COOPS SOS using DescribeSensor\n",
      "    request.\"\"\"\n",
      "    url = ('http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS?service=SOS&'\n",
      "           'request=DescribeSensor&version=1.0.0&'\n",
      "           'outputFormat=text/xml;subtype=\"sensorML/1.0.1\"&'\n",
      "           'procedure=urn:ioos:station:NOAA.NOS.CO-OPS:%s') % sta\n",
      "    tree = etree.parse(urlopen(url))\n",
      "    root = tree.getroot()\n",
      "    path = \"//sml:identifier[@name='longName']/sml:Term/sml:value/text()\"\n",
      "    namespaces = dict(sml=\"http://www.opengis.net/sensorML/1.0.1\")\n",
      "    longName = root.xpath(path, namespaces=namespaces)\n",
      "    if len(longName) == 0:\n",
      "        longName = coops_id\n",
      "    return longName[0]\n",
      "\n",
      "\n",
      "def coops2df(collector, coops_id, sos_name):\n",
      "    \"\"\"Request CSV response from SOS and convert to Pandas DataFrames.\"\"\"\n",
      "    collector.features = [coops_id]\n",
      "    collector.variables = [sos_name]\n",
      "    long_name = get_Coops_longName(coops_id)\n",
      "    \n",
      "    try:\n",
      "        response = collector.raw(responseFormat=\"text/csv\")\n",
      "        data_df = read_csv(BytesIO(response.encode('utf-8')),\n",
      "                           parse_dates=True,\n",
      "                           index_col='date_time')\n",
      "        col = 'water_surface_height_above_reference_datum (m)'\n",
      "        if False:\n",
      "            data_df['Observed Data'] = (data_df[col] -\n",
      "                                        data_df['vertical_position (m)'])\n",
      "        data_df['Observed Data'] = data_df[col]\n",
      "    except ExceptionReport as e:\n",
      "        warn(\"Station %s is not NAVD datum. %s\" % (long_name, e))\n",
      "        data_df = DataFrame()  # Assing an empty DataFrame for now.\n",
      "\n",
      "    data_df.name = long_name\n",
      "    return data_df\n",
      "\n",
      "\n",
      "def mod_df(arr, timevar, istart, istop, mod_name, ts):\n",
      "    \"\"\"Return time series (DataFrame) from model interpolated onto uniform\n",
      "    time base.\"\"\"\n",
      "    t = timevar.points[istart:istop]\n",
      "    jd = timevar.units.num2date(t)\n",
      "\n",
      "    # Eliminate any data that is closer together than 10 seconds this was\n",
      "    # required to handle issues with CO-OPS aggregations, I think because they\n",
      "    # use floating point time in hours, which is not very accurate, so the\n",
      "    # FMRC aggregation is aggregating points that actually occur at the same\n",
      "    # time.\n",
      "    dt = np.diff(jd)\n",
      "    s = np.array([ele.seconds for ele in dt])\n",
      "    ind = np.where(s > 10)[0]\n",
      "    arr = arr[ind+1]\n",
      "    jd = jd[ind+1]\n",
      "\n",
      "    b = DataFrame(arr, index=jd, columns=[mod_name])\n",
      "    # Eliminate any data with NaN.\n",
      "    b = b[np.isfinite(b[mod_name])]\n",
      "    # Interpolate onto uniform time base, fill gaps up to:\n",
      "    # (10 values @ 6 min = 1 hour).\n",
      "    c = concat([b, ts], axis=1).interpolate(limit=10)\n",
      "    return c\n",
      "\n",
      "\n",
      "def dateRange(start_date='1900-01-01', stop_date='2100-01-01',\n",
      "              constraint='overlaps'):\n",
      "    \"\"\"Hopefully something like this will be implemented in fes soon.\"\"\"\n",
      "    if constraint == 'overlaps':\n",
      "        begin = 'apiso:TempExtent_begin'\n",
      "        end = 'apiso:TempExtent_end'\n",
      "        start = fes.PropertyIsLessThanOrEqualTo(propertyname=begin,\n",
      "                                                literal=stop_date)\n",
      "        stop = fes.PropertyIsGreaterThanOrEqualTo(propertyname=end,\n",
      "                                                  literal=start_date)\n",
      "    elif constraint == 'within':\n",
      "        start = fes.PropertyIsGreaterThanOrEqualTo(propertyname=begin,\n",
      "                                                   literal=start_date)\n",
      "        stop = fes.PropertyIsLessThanOrEqualTo(propertyname=end,\n",
      "                                               literal=stop_date)\n",
      "    return start, stop\n",
      "\n",
      "\n",
      "def service_urls(records, service='odp:url'):\n",
      "    \"\"\"Extract service_urls of a specific type (DAP, SOS) from records.\"\"\"\n",
      "    service_string = 'urn:x-esri:specification:ServiceType:' + service\n",
      "    urls = []\n",
      "    for key, rec in records.iteritems():\n",
      "        # Create a generator object, and iterate through it until the match is\n",
      "        # found if not found, gets the default value (here \"none\").\n",
      "        url = next((d['url'] for d in rec.references if\n",
      "                    d['scheme'] == service_string), None)\n",
      "        if url is not None:\n",
      "            urls.append(url)\n",
      "    return urls\n",
      "\n",
      "\n",
      "def nearxy(x, y, xi, yi):\n",
      "    \"\"\"Find the indices x[i] of arrays (x,y) closest to the points (xi,yi).\"\"\"\n",
      "    ind = np.ones(len(xi), dtype=int)\n",
      "    dd = np.ones(len(xi), dtype='float')\n",
      "    for i in np.arange(len(xi)):\n",
      "        dist = np.sqrt((x-xi[i])**2 + (y-yi[i])**2)\n",
      "        ind[i] = dist.argmin()\n",
      "        dd[i] = dist[ind[i]]\n",
      "    return ind, dd\n",
      "\n",
      "\n",
      "def find_ij(x, y, d, xi, yi):\n",
      "    \"\"\"Find non-NaN cell d[j, i] that are closest to points (xi, yi).\"\"\"\n",
      "    index = np.where(~np.isnan(d.flatten()))[0]\n",
      "    ind, dd = nearxy(x.flatten()[index],\n",
      "                     y.flatten()[index], xi, yi)\n",
      "    j, i = ind2ij(x, index[ind])\n",
      "    return i, j, dd\n",
      "\n",
      "\n",
      "def find_timevar(cube):\n",
      "    \"\"\"Return the time variable from Iris.  This is a workaround for\n",
      "    Iris having problems with FMRC aggregations, which produce two time\n",
      "    coordinates.\"\"\"\n",
      "    try:\n",
      "        cube.coord(axis='T').rename('time')\n",
      "    except:\n",
      "        pass\n",
      "    timevar = cube.coord('time')\n",
      "    return timevar\n",
      "\n",
      "\n",
      "def ind2ij(a, index):\n",
      "    \"\"\"Returns a[j,i] for a.ravel()[index].\"\"\"\n",
      "    n, m = a.shape\n",
      "    j = np.ceil(index // m)\n",
      "    i = np.remainder(index, m)\n",
      "    return i, j"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}